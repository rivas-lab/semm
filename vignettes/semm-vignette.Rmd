---
title: "SEMM Example"
author: "E Flynn"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
fig_wdith: 8
fig_height: 6
vignette: >
 %\VignetteIndexEntry{Vignette Title}
 %\VignetteEngine{knitr::rmarkdown}
 \usepackage[utf8]{inputenc}

---

```{r, echo=FALSE, message=FALSE}
require('semm')
```


## Prepare the input data
The method takes as input GWAS summary stats for a quantitative trait from multiple groups. We use the function `prep_gwas_input()` to reformat the summary statistic files into an input object for the models. Prior to loading the data, please make sure that the summary statistic data is flip-fixed so allele effect sizes refer to the same REF/ALT pairs.

Here we are looking at sex-differential effects - so the summary statistics should come from running GWAS separately on males and females.
SEMM uses the ID (variant), BETA (effect size), SE, CHR (chromosome), and P columns from summary statistics. IDs, BETAs and SEs are strictly required; we suggest including CHR and P for examining the output.

We can also use more than two categories - e.g. pre and post-menopausal women and men, or multiple different age or other buckets. To do this, just include a longer list of `gwas.files` and `cat.labels` associated with the files. Note that each summary statistic file must have been generated by running GWAS on only that group.

Here are two mock files.
```{r, message=FALSE}

f.file <- system.file("extdata", "ex_chr6_f_test.txt.gz", package = "semm")
m.file <-  system.file("extdata", "ex_chr6_m_test.txt.gz", package = "semm")
head(readr::read_tsv(f.file))
head(readr::read_tsv(m.file))
```
As you can see, the appropriate columns are specified; they can be in any ordered. If they have alternate names, just specify this as additional arguments for the `prep_gwas_input()` function -- e.g. `"BETA"="B"`, `"CHR"="#CHROM#` -- and the function will parse these columns.

The model assumes that the input variants have been **LD filtered** prior to fitting the model. This can be done either by pre-filtering the input data or providing a list of variants to keep using the `var.keep` option. If this list is not provided, all variants will be kept.

Here we are filtering out variants in LD and that have >1\% missingness. We have also added a random selection of variants to remove so that this will run in an reasonable amount of time for this example.

We use a standard error cutoff `se.cut` of 0.2 to remove variants with high standard errors.

To make our output easier to read, we can specify the names of the categories using `cat.labels`; they should correspond to the order of the files provided. Here they are `female` and `male`.
```{r, message=FALSE}
# read in the variants to keep
var_keep_file <- system.file("extdata", "ex_var_to_keep.txt.gz", package = "semm")
var_keep_ex <- readr::read_tsv(var_keep_file, col_names=FALSE)$X1
head(var_keep_ex)

dat <- prep_gwas_input(c(f.file, m.file), se.cut = 0.2, var.keep=var_keep_ex, cat.labels=c("female", "male"), CHR="#CHROM", B="BETA")
```

The function `prep_gwas_input()` reformats the data into a list containing $n$ x $m$ matrices of betas and standard errors where $n$ is the number of variants and $m$ is the number of files or categories. Each row in the matrix is a variant, and the columns are are from the files. 
```{r}
str(dat)
head(dat$B)
```

We can then use this reformatted data object as input for fitting the models.

## Two-component model to estimate genetic correlation and heritability
We call this `model 1`. This is a two-component mixture model consisting of a point mass centered at zero and a multivariate normal distribution. The $\beta$ and $SE$ values are from the summary statistics. 

$$ M_0 = \left[\begin{array}{c} \hat{\beta}_{f} \\ \hat{\beta}_{m} \end{array}\right] \sim N \left( 0, \begin{bmatrix} \hat{SE}^2_{f}  & 0 \\ 0 & \hat{SE}^2_{m} \end{bmatrix} \right)$$
$$M_1 = \left[\begin{array}{c} \hat{\beta}_{f} \\ \hat{\beta}_{m} \end{array}\right] \sim N \left( 0, \begin{bmatrix} \hat{SE}^2_{f}  & 0 \\ 0 & \hat{SE}^2_{m} \end{bmatrix}  + \begin{bmatrix} \sigma^2_f & \rho {\sigma}_f  \sigma_m  \\ \rho {\sigma}_f  \sigma_m  & \sigma^2_m \end{bmatrix}\right)$$

We use this model to estimate $\pi$, the proportion in each component, and $\Sigma$, the variance-covariance matrix of the non-null component. In the process, we also estimate the *genetic correlation*. We can use $\pi$ and $\Sigma$ to look at the posterior probability of a variant being assigned to the non-null component and estimate *heritability*.

### Train the two-component model

We can now train the 2-component model using the inputted data. We use the function `model1_stan(dat, ...)` (it is also possible to directly provide betas and standard errors to model1 using the options "B" and "SE). 

Additional arguments provided to the function are STAN specifications. 
We recommend checking the [STAN user's guide](https://mc-stan.org/docs/2_18/stan-users-guide/) for more information about the arguments to provide.

Here we are using 4 chains, 800 total iterations, and 200 warmup iterations.
If we run this on a multi-core machine, it is helpful to set it up to run the chains in parallel using the `options` command. 

When this starts running, STAN will print out the estimated amount of time for running this. This will be in the form of:
```
Chain 1: Gradient evaluation took 0.031815 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 318.15 seconds.
```
This will give you an estimate of how long it will take to fit the model. If you are not running this in parallel, it will take that amount of time for each chain.

We are using a toy example, still this takes about 5 minutes to fit on my computer, which has a four-core 3.1 GHz processor and 16 GB RAM. The amount of time to fit increases with increasing numbers of variants; for most genome-scale analyses, using LD-filtered data, you will want to submit this to a cluster. The analysis performed in the paper including ~300,000 variants and took approximately 12-15 hours w 30 GB RAM and 4 cores to run for each trait.

```{r}
#options(mc.cores = parallel::detectCores()) # use if multi-core
#fit1 <- model1_stan(dat, chains=4, warmup=200, iter=800, refresh=200, cores=4)
load(system.file("extdata", "fit1.RData", package = "semm"))
```

We recommend saving the fit so you can go back to it if you need. 


### Examine the model fit
It is important to check the model for convergence. As a quick check, make sure the `Rhat` values are close to 1 and the `n_eff` values are not small, and check the traceplot to see that it converges. Please refer to the [stan reference manual](https://mc-stan.org/docs/2_18/reference-manual/) for more information about this. The output is an object of class stanfit; there are many ways to examine this output, including printing the summary and viewing the traceplot for the parameters.

```{r}
# We care about these three parameters: "pi", "Sigma", "Omegacor"
#  Omegacor[1,2] is the genetic correlation

# view the summary
print(fit1, pars=c("pi", "Sigma", "Omegacor[1,2]"), digits=5)

# print the traceplots
rstan::traceplot(fit1, pars=c("pi", "Sigma", "Omegacor[1,2]"))
```

### Extract the parameter fit, heritability, and genetic correlation

Now that we've examined the fit and we're happy with it, let's extract the fitted parameters.
```{r}
fit_params <- extract_fit_params(fit1, dat)
fit_params$prop # proportion in each component: null, non-null (pi)
fit_params$var_cov # the variance-covariance matrix (Sigma)

fit_params$gen_cor # or use `get_gen_cor(fit1)` (off-diagonal for Omegacor)
get_gen_cor_ci(fit1) # gives the 95% hpd interval for the genetic correlation
```


A genetic correlation close to one indicates traits are highly shared between the two categories (female and male in this case). 

To get the heritability, we rely on assigning variants to components. First, we need to calculate the posterior probability a variant belongs to the non-null component.
```{r}
posterior.df <- calc_posteriors(fit1, dat) 
head(posterior.df) # p1 is the probability it belongs to the non-null component
```

Then, we can select a cutoff for which we assign the variant to the non-null component (we generally use 0.8), and use that to calculate the heritability for females and males separately. The heritability will be labeled for each category.
```{r}
herit <- calc_heritability(fit1, dat, posterior.df, cutoff=0.8)
herit 
```

## Four component model identify sex-specific variants
`model2` is a four-component model that we use to identify variants with "sex-specific" effects. “sex-specific” effects indicate that the effect of these variants in males is different from that in females -- e.g. this variant is associated with higher values of a trait in females but not in males, while a “shared” effect would mean that the same genetic variant or set of variants have the same effect in males and females. 

The four components are as follows, where $\beta \neq 0$: \\
$k = 0, \beta_m = \beta_f = 0$           No effect \\
$k = 1, \beta_m =\beta, \beta_m=0$     Female-specific effect \\
$k=2, \beta_f = 0, \beta_m = \beta$      Male-specific effect \\
$k=3, \beta_m = \beta, \beta_f = \beta $      Effects in both sexes \\


### Train the four-component model
We use the same data object to train model2. Model2 only works for two category data (e.g. males and females), it has yet to be extended to more than two categories.
Note that model2 takes longer to fit than model1. This took about 12 minutes on my computer; running with 300,000 variants takes
```{r}

#fit2 <- model2_stan(dat, chains=4, warmup=200, iter=800, refresh=200)
load(system.file("extdata", "fit2.RData", package = "semm"))


```

It is important to examine the model fit for convergence.
This model works very well in cases that there are highly polygenic sex-specific effects, but has poor performance if there are few sex-specific effects.
```{r}
# we care about these parameters: "pi", "sigmasq"
# sigmasq is the variances for each of the components 

# view the summary
print(fit2, pars=c("pi", "sigmasq"), digits=5)

# print the traceplots
rstan::traceplot(fit2, pars=c("pi", "sigmasq"))
```

### Extract the parameter fit and the sex-specific variants
We can then view the extracted values from these fits:
```{r}
fit_params2 <- extract_fit_params(fit2, dat)
fit_params2$prop # the proportion assigned to each
fit_params2$vars # the variances 
```

Finally, we examine the variant assignment. We first calculate the posterior probaility for each variant being in a particular category. 
```{r}
posterior.df2 <- calc_posteriors(fit2, dat)
head(posterior.df2)
```

We then use this and a set posterior cutoff to assign variants to a non-null component (we have used 0.8). We then can summarize this information with the original inputted betas and standard errors to create an easy to view output table. 
```{r}
var.df <- make_var_table(dat, posterior.df2, cutoff = 0.8)
table(var.df$component)
head(var.df)
```

Each posterior cutoff has an associated false-discovery rate for each non-null component. We calculate this with `calc_fdr()` - and can do for a range of posterior cutoffs to get a picture of what we are examining. We can also get the FDR for the model 1 non-null component.
```{r, message=FALSE}
calc_fdr(posterior.df, cutoff=0.6) # model 1
calc_fdr(posterior.df2, cutoff=0.8) # model 2
```

We can also view the betas and standard errors in a plot, colored by component assignment.
```{r}
beta_compare_plot(var.df, dat)
```
